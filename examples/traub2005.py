# traub2005.py --- 
# 
# Filename: traub2005.py
# Description: 
# Author: Subhasis Ray
# Maintainer: 
# Created: Sat Aug  9 16:10:00 2014 (+0530)
# Version: 
# Last-Updated: 
#           By: 
#     Update #: 0
# URL: 
# Keywords: 
# Compatibility: 
# 
# 

# Commentary: 
# 
# 
# 
# 

# Change log:
# 
# 
# 
# 
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation; either version 3, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program; see the file COPYING.  If not, write to
# the Free Software Foundation, Inc., 51 Franklin Street, Fifth
# Floor, Boston, MA 02110-1301, USA.

# 
# 

# Code:
"""This creates a reduced version of Traub et al 2005 cortical model
and some example data for the same.

The model in this current instance is a dummy-one created in
Python. For the original model see modeldb.

"""

import os
import random
from uuid import uuid1
from collections import defaultdict
from datetime import datetime
import numpy as np

import sys
sys.path.append('..')

import nsdf

CELL_POPS = ( # The columns are:

    # Cell, number, compartments, presynaptic-compartment-no
    
    # presynaptic-compartment no. is counted from 1, so we subtract 1
    # when actually using the number.
    ('SupPyrRS',    	1000, 74, 72),	# L2/3 excitatory neuron
    ('SupPyrFRB',   	50,   74, 72),	# L2/3 excitatory neuron
    ('SupBasket',   	90,   59, 59),	# L2/3 Inhibitory GABAergic interneuron
    ('SupAxoaxonic',	90,   59, 59),	# L2/3 Inhibitory GABAergic Chandelier interneuron
    ('SupLTS',      	90,   59, 59),	# L2/3 Low-Threshold-Spiking Inhibitory GABAergic interneuron
    ('SpinyStellate',   240,  59, 57),   # L4 excitatory cells - get inputs from thalamus
    ('TuftedIB',    	800,  61, 60),	# L5 excitatory
    ('TuftedRS',    	200,  61, 60),	# L5 excitatory
    ('DeepBasket',  	100,  59, 59),	# L5 inhibitory
    ('DeepAxoaxonic',   100,  59, 59),   # L5 inhibitory
    ('DeepLTS',     	100,  59, 59),	# L5 inhibitory
    ('NontuftedRS', 	500,  50, 48),	# L6 excitatory
    ('TCR',         	100,  137,135),	# Thalamic excitatory
    ('nRT',          	100,   59, 59)	# Thalamic excitatory
)

class ComponentBase(nsdf.ModelComponent):
    """This class just adds an autogenerated unique numeric id to
    nsdf.ModelComponent"""
    def __init__(self, *args, **kwargs):
        kwargs['uid'] = uuid1().hex
        nsdf.ModelComponent.__init__(self, *args, **kwargs)
        
class HHChannel(ComponentBase):
    """Base class of ion channels."""
    def __init__(self, *args, **kwargs):
        ComponentBase.__init__(self, *args, **kwargs)
        self.attrs['ontology'] = 'cno_0000047'

        
class CaConc(ComponentBase):
    def __init__(self, *args, **kwargs):
        ComponentBase.__init__(self, *args, **kwargs)
        self.attrs['ontology'] = 'cno_0000056'

        
class SynChan(ComponentBase):
    def __init__(self, *args, **kwargs):
        ChanBase.__init__(self, *args, **kwargs)
        
    
class Compartment(ComponentBase):        
    """Class for compartment."""
    def __init__(self, *args, **kwargs):
        ComponentBase.__init__(self, *args, **kwargs)

        
class Neuron(ComponentBase):
    """Base class for all the cell types.
    
    """
    def __init__(self, *args, **kwargs):
        ncomp = kwargs.pop('ncomp', 0)
        presyn = kwargs.pop('presyn', 0)
        ComponentBase.__init__(self, *args, **kwargs)        
        self.attrs['ontology'] = 'cno_0000020'
        self.presyn = presyn
        self.compartments = []
        for ii in range(ncomp):
            child = Compartment('compartment_{}'.format(ii), parent=self)
            self.compartments.append(child)
            
class ThalamoCorticalModel(ComponentBase):
    """Model tree for Thalamocortical Model by Traub et al 2005.

    This creates components up to the level of compartments and does
    not handle channels. Adding the channels will involve reading
    prototype files with explicit specification of which compartments
    have which channels.

    """
    def __init__(self, *args, **kwargs):
        ComponentBase.__init__(self, *args, **kwargs)
        print 'Start model creation'
        self.cellgroup = {}
        self.cells = defaultdict(list)
        for (celltype, cellcount, compcount, presyn) in CELL_POPS:
            group = ComponentBase(celltype, parent=self)
            self.cellgroup[celltype] = group
            for ii in range(cellcount):
                cell = Neuron('{}_{}'.format(celltype, ii),
                              parent=group, ncomp=compcount,
                              presyn=presyn)
                self.cells[celltype].append(cell)
        print 'End model creation'


dialect_eventds_map = {
    nsdf.dialect.ONED: nsdf.NSDFWriter.add_event_ds_1d,
    nsdf.dialect.VLEN: nsdf.NSDFWriter.add_event_ds,
    nsdf.dialect.NANPADDED: nsdf.NSDFWriter.add_event_ds,
    nsdf.dialect.NUREGULAR: nsdf.NSDFWriter.add_event_ds                            
}

dialect_nonuniformds_map = {
    nsdf.dialect.ONED: nsdf.NSDFWriter.add_nonuniform_ds_1d,
    nsdf.dialect.VLEN: nsdf.NSDFWriter.add_nonuniform_ds,
    nsdf.dialect.NANPADDED: nsdf.NSDFWriter.add_nonuniform_ds,
    nsdf.dialect.NUREGULAR: nsdf.NSDFWriter.add_nonuniform_ds                            
}

dialect_eventwriter_map = {
    nsdf.dialect.ONED:  nsdf.NSDFWriter.add_event_1d,
    nsdf.dialect.VLEN: nsdf.NSDFWriter.add_event_vlen,
    nsdf.dialect.NANPADDED: nsdf.NSDFWriter.add_event_nan,
    nsdf.dialect.NUREGULAR: nsdf.NSDFWriter.add_event_1d                            
}

dialect_nuwriter_map = {
    nsdf.dialect.ONED:  nsdf.NSDFWriter.add_nonuniform_1d,
    nsdf.dialect.VLEN: nsdf.NSDFWriter.add_nonuniform_vlen,
    nsdf.dialect.NANPADDED: nsdf.NSDFWriter.add_nonuniform_nan,
    nsdf.dialect.NUREGULAR: nsdf.NSDFWriter.add_nonuniform_regular                       
}

model = ThalamoCorticalModel('thalamocortical')
EVENT_MAX = 1000 # maximum number of events

FLOATDTYPE = np.float32

def create_example(dialect=nsdf.dialect.ONED, simtime=10.0, dt=1e-4):
    """Create a sample NSDF file using the specified dialect.

    The file stores the model tree (down to single compartments) and

    spike times from all the cells, categorized into populations by
    celltype.
    
    Vm for 10% of the cells of each type as uniformly sampled data.

    """
    start_time = datetime.now()
    writer = nsdf.NSDFWriter('traub_et_al_2005_{}.h5'.format(dialect),
                             mode='w', dialect=dialect)
    print 'Start add_modeltree'
    writer.add_modeltree(model)
    print 'End add_modeltree'
    for celltype, cell_list in model.cells.items():
        event_sources = [cell.compartments[cell.presyn - 1]     \
                         for cell in cell_list]
        event_data = nsdf.EventData('spiketime', unit='s', dtype=FLOATDTYPE)
        for src in event_sources:
            num_spikes = np.random.randint(EVENT_MAX)
            times = np.cumsum(np.random.exponential(1/10.0,
                                                    size=num_spikes))
            times = times[times < simtime].copy()
            event_data.put_data(src.uid, times)
        if dialect in (nsdf.dialect.ONED, nsdf.dialect.NUREGULAR):
            event_ds = writer.add_event_ds_1d(celltype, 'spiketime',
                                              event_data.get_sources())
            writer.add_event_1d(event_ds, event_data)
        else:
            event_ds = writer.add_event_ds(celltype,
                                           event_data.get_sources())
            dialect_eventwriter_map[dialect](writer,
                                             event_ds,
                                             event_data)
        vm_sources = random.sample(event_sources, len(event_sources)/10)
        vm_data = nsdf.UniformData('Vm', unit='V', field='Vm')
        vm_data.set_dt(dt, unit='s')
        for src in vm_sources:
            vm = np.random.uniform(-120e-3, 40e-3, size=simtime/dt)
            vm_data.put_data(src.uid, vm)
        vm_ds = writer.add_uniform_ds(celltype, vm_data.get_sources())
        writer.add_uniform_data(vm_ds, vm_data)
    end_time = datetime.now()
    writer.set_title('Sample NSDF file for Traub et al 2005 model')
    writer.set_description('This file uses {} dialect of NSDF'.format(dialect))
    writer.set_tstart(start_time)
    writer.set_tend(end_time)
    writer.set_creator([os.environ['USER']])
    writer.set_license('CC BY-SA')
    writer.set_software(['Python2.7', 'nsdf python library'])
    print 'Finished writing example NSDF file for dialect {}'.format(dialect)


if __name__ == '__main__':
    create_example(dialect=nsdf.dialect.ONED)
    create_example(dialect=nsdf.dialect.VLEN)
    create_example(dialect=nsdf.dialect.NANPADDED)
    create_example(dialect=nsdf.dialect.NUREGULAR)

# 
# traub2005.py ends here


